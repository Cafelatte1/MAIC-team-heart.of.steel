{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOBAL_SEED = 42\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = str(GLOBAL_SEED)\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random as np_rnd\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random as rnd\n",
    "import pickle\n",
    "import gc\n",
    "import time\n",
    "from itertools import product\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import catboost as cat\n",
    "from sklearn import metrics as skl_metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "from helper_functions import *\n",
    "\n",
    "class CFG:\n",
    "    debug = False\n",
    "    dataset_root_path = \"./dataset/\"\n",
    "    dataset_version = \"v5\"\n",
    "    model_root_path = \"./models/\"\n",
    "    n_comp = 64\n",
    "    TF = False\n",
    "    TF_type = \"indiv\"\n",
    "    use_ecg_stats = False\n",
    "    use_ecg_seq = True\n",
    "    pca_seq = False\n",
    "    n_folds = 1 if debug else 5\n",
    "    lead_names = [\"std1\", \"std2\", \"std3\", \"v1\", \"v2\", \"v3\", \"v4\", \"v5\", \"v6\", \"augvr\", \"augvl\", \"augvf\"]\n",
    "    ecg_hz = 500\n",
    "\n",
    "    epochs = 2 if debug else 30\n",
    "    early_stopping_rounds = 10\n",
    "    batch_size = 32\n",
    "    eta = 5e-4\n",
    "    weight_decay = 1e-4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, feature_seq, feature_meta, label=None):\n",
    "        self.feature_seq = feature_seq\n",
    "        self.feature_meta = feature_meta\n",
    "        self.label = np.ones(len(feature_seq)) if label is None else label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\"seq\": self.feature_seq[idx], \"meta\": self.feature_meta[idx], \"label\": self.label[idx]}\n",
    "\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_c, in_out, kernel_size=5, stride=1, act=nn.ReLU()):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_c),\n",
    "            act,\n",
    "            nn.Conv1d(in_c, in_c, kernel_size=1, groups=in_c, padding=\"same\"),\n",
    "            nn.BatchNorm1d(in_c),\n",
    "            act,\n",
    "            nn.Conv1d(in_c, in_out, kernel_size=kernel_size, stride=stride, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_c + in_out),\n",
    "            act,\n",
    "            nn.Conv1d(in_c + in_out, in_c + in_out, kernel_size=1, groups=in_c + in_out, padding=\"same\"),\n",
    "            nn.BatchNorm1d(in_c + in_out),\n",
    "            act,\n",
    "            nn.Conv1d(in_c + in_out, in_out, kernel_size=kernel_size, stride=stride, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_c + in_out * 2),\n",
    "            act,\n",
    "            nn.Conv1d(in_c + in_out * 2, in_c + in_out * 2, kernel_size=1, groups=in_c + in_out * 2, padding=\"same\"),\n",
    "            nn.BatchNorm1d(in_c + in_out * 2),\n",
    "            act,\n",
    "            nn.Conv1d(in_c + in_out * 2, in_out, kernel_size=kernel_size, stride=stride, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_c + in_out * 3),\n",
    "            act,\n",
    "            nn.Conv1d(in_c + in_out * 3, in_c + in_out * 3, kernel_size=1, groups=in_c + in_out * 3, padding=\"same\"),\n",
    "            nn.BatchNorm1d(in_c + in_out * 3),\n",
    "            act,\n",
    "            nn.Conv1d(in_c + in_out * 3, in_out, kernel_size=kernel_size, stride=stride, padding=\"same\"),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(torch.cat([x, x1], dim=1))\n",
    "        x3 = self.conv3(torch.cat([x, x1, x2], dim=1))\n",
    "        x4 = self.conv4(torch.cat([x, x1, x2, x3], dim=1))\n",
    "        return x4\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, pool_size):\n",
    "        super(TransitionLayer,self).__init__()\n",
    "        self.pooling = nn.AvgPool1d(kernel_size=pool_size)\n",
    "    def forward(self, x):\n",
    "        return self.pooling(x)\n",
    "\n",
    "class DNN_CustomModel(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        act = nn.LeakyReLU() if params[\"act\"] == \"leakyrelu\" else nn.ReLU()\n",
    "        self.input_transition = nn.Sequential(\n",
    "            nn.BatchNorm1d(params[\"seq_n_features\"]),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv1d(params[\"seq_n_features\"], params[\"base_hidden_layers\"] * 1, kernel_size=5, stride=3, padding=\"valid\"),\n",
    "            nn.AdaptiveAvgPool1d(256),\n",
    "        )\n",
    "\n",
    "        self.dense_blocks = []\n",
    "        in_c = params[\"base_hidden_layers\"] * 1\n",
    "        for size_multiplier in [2, 4, 6, 8]:\n",
    "            self.dense_blocks.append(nn.Sequential(\n",
    "                DenseBlock(in_c, params[\"base_hidden_layers\"] * size_multiplier, kernel_size=3, stride=1, act=act),\n",
    "                TransitionLayer(2),\n",
    "            ))\n",
    "            in_c = params[\"base_hidden_layers\"] * size_multiplier\n",
    "        self.dense_blocks = nn.Sequential(*self.dense_blocks)\n",
    "        self.lstm = nn.LSTM(in_c, params[\"lstm_hidden_layers\"], num_layers=2, batch_first=True)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(params[\"dropoutRate\"]),\n",
    "            nn.Linear((params[\"lstm_hidden_layers\"] * 16), params[\"concat_hidden_layers\"]),\n",
    "            act,\n",
    "            nn.Dropout(params[\"dropoutRate\"]),\n",
    "            nn.Linear(params[\"concat_hidden_layers\"], params[\"concat_hidden_layers\"]//4),\n",
    "            act,\n",
    "        )\n",
    "        self.regressor = nn.Linear(params[\"concat_hidden_layers\"]//4, 1)\n",
    "\n",
    "    def forward(self, seq, meta):\n",
    "        x = self.input_transition(seq)\n",
    "        x = self.dense_blocks(x)\n",
    "        x = torch.permute(x, (0, 2, 1))\n",
    "        x, _ = self.lstm(x, self.init_states(len(x)))\n",
    "        seq_embed = self.flatten(x)\n",
    "        x = self.fc(seq_embed)\n",
    "        return seq_embed, self.regressor(x)\n",
    "\n",
    "    def init_states(self, batch_size):\n",
    "        h0 = torch.zeros((2, batch_size, self.params[\"lstm_hidden_layers\"]), dtype=torch.float32).to(device)\n",
    "        c0 = torch.zeros((2, batch_size, self.params[\"lstm_hidden_layers\"]), dtype=torch.float32).to(device)\n",
    "        return (h0, c0)\n",
    "\n",
    "\n",
    "def get_embeddings(model, dl):\n",
    "    output = []\n",
    "    for batch in tqdm(dl):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            output.append(model(seq=batch[\"seq\"], meta=batch[\"meta\"])[0].detach().cpu().numpy())\n",
    "    return np.concatenate(output)\n",
    "\n",
    "ntrees = 100 if CFG.debug else 5000\n",
    "eta = 5e-3\n",
    "\n",
    "fixed_params = {\n",
    "    \"boosting_type\": \"Plain\",\n",
    "    \"loss_function\": \"RMSE\",\n",
    "    \"eval_metric\": \"RMSE\",\n",
    "    \"bootstrap_type\": \"Bayesian\",\n",
    "    \"n_estimators\": ntrees,\n",
    "    \"learning_rate\": eta,\n",
    "    \"max_depth\": 8,\n",
    "    \"verbose\": False,\n",
    "    \"task_type\": \"GPU\",\n",
    "    \"use_best_model\": True,\n",
    "}\n",
    "dynamic_params = {\n",
    "    \"reg_lambda\": [1.0],\n",
    "}\n",
    "\n",
    "class CAT_CustomModel():\n",
    "    def __init__(self, output_average=\"best\"):\n",
    "        # available options : \"all\", \"best\"\n",
    "        self.output_average = output_average\n",
    "        self.model_list = []\n",
    "        self.eval_score_list = []\n",
    "        self.ntrees = ntrees\n",
    "        for idx, params in enumerate(product(*dynamic_params.values())):\n",
    "            tmp_params = fixed_params.copy()\n",
    "            tmp_params.update({k: v for k, v in zip(dynamic_params.keys(), params)})\n",
    "            self.model_list.append(cat.CatBoostRegressor(**tmp_params))\n",
    "    def fit(self, x, y, groups, eval_x, eval_y, eval_groups):\n",
    "        for model in tqdm(self.model_list, desc=\"Training...\"):\n",
    "            model.fit(\n",
    "                x, y,\n",
    "                eval_set=[(eval_x, eval_y)],\n",
    "                early_stopping_rounds=int(self.ntrees * 0.2), verbose=0,\n",
    "            )\n",
    "            y_pred = model.predict(eval_x)\n",
    "            self.eval_score_list.append(skl_metrics.mean_absolute_error(eval_y, y_pred))\n",
    "        print(\"=== Best model & Score ===\")\n",
    "        print(\"Model :\", self.model_list[np.argmin(self.eval_score_list)])\n",
    "        print(\"MAE :\", self.eval_score_list[np.argmin(self.eval_score_list)])\n",
    "        print(\"Best Trees :\", self.model_list[np.argmin(self.eval_score_list)].get_best_iteration())\n",
    "    def predict(self, x):\n",
    "        if self.output_average == \"all\":\n",
    "            return np.stack([model.predict(x) for model in self.model_list], axis=0).mean(axis=0), self.eval_score_list[np.argmin(self.eval_score_list)]\n",
    "        else:\n",
    "            return self.model_list[np.argmin(self.eval_score_list)].predict(x), self.eval_score_list[np.argmin(self.eval_score_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_root_path = \"./models/\"\n",
    "dataset_root_path = \"./dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading test metadata\n",
    "df_test = pd.concat([\n",
    "    pd.read_csv(CFG.dataset_root_path + \"submission.csv\"),\n",
    "], axis=0).reset_index(drop=True)\n",
    "df_test.columns = df_test.columns.str.lower()\n",
    "df_test[\"age_type\"] = df_test[\"filename\"].apply(lambda x: x.split(\"_\")[1].split(\"_\")[0])\n",
    "df_test[\"gender\"] = df_test[\"gender\"].apply(lambda x: 1 if x == \"MALE\" else 0)\n",
    "df_test[\"age_type\"] = df_test[\"age_type\"].apply(lambda x: 1 if x == \"adult\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5475/5475 [00:02<00:00, 1998.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# loading test ecg sequence data\n",
    "test_ecg_seq_feature = []\n",
    "for fpath in tqdm(df_test[\"filename\"]):\n",
    "    df_ecg = np.load(CFG.dataset_root_path + f\"ECG_{fpath.split('_')[1].split('_')[0]}_numpy_valid/{fpath}.npy\").astype(\"float32\")\n",
    "    df_ecg = np.stack([df_ecg[((lead + 0) * 5000):((lead + 1) * 5000)] for lead in range(12)], axis=0)\n",
    "    test_ecg_seq_feature.append(F.avg_pool1d(torch.from_numpy(df_ecg), 10, 10).detach().cpu().numpy())\n",
    "test_ecg_seq_feature = np.stack(test_ecg_seq_feature, axis=0)\n",
    "test_fnames = df_test[\"filename\"].values\n",
    "df_test = df_test.drop(\"filename\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling\n",
    "scaler_seq = pickleIO(None, CFG.model_root_path + \"scaler_seq.pkl\", \"r\")\n",
    "for target in df_test[\"age_type\"].unique():\n",
    "    tmp = test_ecg_seq_feature[(df_test[\"age_type\"] == target).values]\n",
    "    for i in range(len(CFG.lead_names)):\n",
    "        tmp[:, i] = (tmp[:, i] - scaler_seq[target][i][\"min\"]) / (scaler_seq[target][i][\"max\"] - scaler_seq[target][i][\"min\"])\n",
    "    test_ecg_seq_feature[df_test[\"age_type\"] == target] = tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:04<00:00,  3.63it/s]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.70it/s]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.70it/s]\n",
      "100%|██████████| 18/18 [00:05<00:00,  3.53it/s]\n",
      "100%|██████████| 18/18 [00:04<00:00,  3.76it/s]\n",
      "100%|██████████| 69/69 [00:19<00:00,  3.51it/s]\n",
      "100%|██████████| 69/69 [00:19<00:00,  3.51it/s]\n",
      "100%|██████████| 69/69 [00:20<00:00,  3.42it/s]\n",
      "100%|██████████| 69/69 [00:20<00:00,  3.39it/s]\n",
      "100%|██████████| 69/69 [00:19<00:00,  3.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# get embedding vector from pretrained-DNN model\n",
    "model_params = pickleIO(None, CFG.model_root_path + \"model_params.pkl\", \"r\")\n",
    "seq_embed = np.zeros((len(df_test), 1024), dtype=\"float32\")\n",
    "for target in df_test[\"age_type\"].unique():\n",
    "    target_name = \"adult\" if target == 1 else \"child\"\n",
    "    target_seq = test_ecg_seq_feature[(df_test[\"age_type\"] == target).values]\n",
    "    target_meta = df_test[(df_test[\"age_type\"] == target).values]\n",
    "    ds = CustomDataset(\n",
    "        feature_seq=target_seq.astype(\"float32\"),\n",
    "        feature_meta=target_meta.drop([\"age\", \"age_type\"], axis=1).values.astype(\"float32\"),\n",
    "        label=None\n",
    "    )\n",
    "    embed = []\n",
    "    for fold in range(5):\n",
    "        model = DNN_CustomModel(model_params)\n",
    "        model.load_state_dict(torch.load(CFG.model_root_path + f\"dnn_rawWithkaggle_densenetLSTM_v2/model_target{target_name}_fold{fold}_best.pth\", map_location=\"cpu\")[\"model\"])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        embed.append(get_embeddings(model, DataLoader(ds, batch_size=64, shuffle=False)))\n",
    "    embed = np.stack(embed, axis=0).mean(axis=0)\n",
    "    seq_embed[(df_test[\"age_type\"] == target).values] = embed\n",
    "del ds, model, embed, test_ecg_seq_feature\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FOLD 0 ===\n",
      "\n",
      "=== FOLD 1 ===\n",
      "\n",
      "=== FOLD 2 ===\n",
      "\n",
      "=== FOLD 3 ===\n",
      "\n",
      "=== FOLD 4 ===\n",
      "\n",
      "=== FOLD 0 ===\n",
      "\n",
      "=== FOLD 1 ===\n",
      "\n",
      "=== FOLD 2 ===\n",
      "\n",
      "=== FOLD 3 ===\n",
      "\n",
      "=== FOLD 4 ===\n"
     ]
    }
   ],
   "source": [
    "# inference\n",
    "test_pred_container = {}\n",
    "for target in df_test[\"age_type\"].unique():\n",
    "    test_pred_container[target] = []\n",
    "    target_name = \"adult\" if target == 1 else \"child\"\n",
    "    for fold in range(CFG.n_folds):\n",
    "        print(f\"\\n=== FOLD {fold} ===\")\n",
    "        seed_everything(fold)\n",
    "        df_test_x = df_test[(df_test[\"age_type\"] == target).values].drop([\"age_type\", \"age\"], axis=1).reset_index(drop=True)\n",
    "        df_test_seq = seq_embed[(df_test[\"age_type\"] == target).values]\n",
    "        model = pickleIO(None, CFG.model_root_path + f\"dnn_rawWithkaggle_catboost_v2/fold{fold}_target{target}_model.pkl\", 'r')\n",
    "        test_pred_container[target].append(model.predict(df_test_seq)[0])\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.loc[df_test[\"age_type\"] == 1, \"age\"] = np.stack(test_pred_container[1], axis=0).mean(axis=0)\n",
    "df_test.loc[df_test[\"age_type\"] == 0, \"age\"] = np.stack(test_pred_container[0], axis=0).mean(axis=0)\n",
    "df_test[\"age\"] = np.clip(df_test[\"age\"], 0.0, 122.0)\n",
    "df_test[\"filename\"] = test_fnames\n",
    "df_test[[\"filename\", \"age\"]].to_csv(\"./result.csv\", index=False, encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>age_type</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.468522</td>\n",
       "      <td>0</td>\n",
       "      <td>ecg_child_8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4.492189</td>\n",
       "      <td>0</td>\n",
       "      <td>ecg_child_8782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4.604526</td>\n",
       "      <td>0</td>\n",
       "      <td>ecg_child_8783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>5.368819</td>\n",
       "      <td>0</td>\n",
       "      <td>ecg_child_8784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.332230</td>\n",
       "      <td>0</td>\n",
       "      <td>ecg_child_8785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470</th>\n",
       "      <td>0</td>\n",
       "      <td>31.693443</td>\n",
       "      <td>1</td>\n",
       "      <td>ecg_adult_39536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5471</th>\n",
       "      <td>0</td>\n",
       "      <td>58.396472</td>\n",
       "      <td>1</td>\n",
       "      <td>ecg_adult_39537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5472</th>\n",
       "      <td>0</td>\n",
       "      <td>50.104998</td>\n",
       "      <td>1</td>\n",
       "      <td>ecg_adult_39538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5473</th>\n",
       "      <td>0</td>\n",
       "      <td>50.283148</td>\n",
       "      <td>1</td>\n",
       "      <td>ecg_adult_39539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5474</th>\n",
       "      <td>0</td>\n",
       "      <td>52.835245</td>\n",
       "      <td>1</td>\n",
       "      <td>ecg_adult_39540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5475 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender        age  age_type         filename\n",
       "0          0   0.468522         0   ecg_child_8781\n",
       "1          1   4.492189         0   ecg_child_8782\n",
       "2          1   4.604526         0   ecg_child_8783\n",
       "3          0   5.368819         0   ecg_child_8784\n",
       "4          0   0.332230         0   ecg_child_8785\n",
       "...      ...        ...       ...              ...\n",
       "5470       0  31.693443         1  ecg_adult_39536\n",
       "5471       0  58.396472         1  ecg_adult_39537\n",
       "5472       0  50.104998         1  ecg_adult_39538\n",
       "5473       0  50.283148         1  ecg_adult_39539\n",
       "5474       0  52.835245         1  ecg_adult_39540\n",
       "\n",
       "[5475 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
